{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import csv\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename, data=\"train\"):\n",
    "    with open(filename) as training_file:\n",
    "        csv_reader = csv.reader(training_file, delimiter=',')\n",
    "        next(csv_reader)\n",
    "        temp_features = []\n",
    "        temp_labels = []\n",
    "        val_feat = []\n",
    "        val_lab = []\n",
    "        t = 0\n",
    "        for row in csv_reader:\n",
    "            if data == \"train\":\n",
    "                if t<450:\n",
    "                    temp_features.append(row[1:-1])\n",
    "                    temp_labels.append(row[-1])\n",
    "                    t += 1\n",
    "                else:\n",
    "                    val_feat.append(row[1:-1])\n",
    "                    val_lab.append(row[-1])\n",
    "                    \n",
    "                    \n",
    "            else:\n",
    "                temp_features.append(row[1:])\n",
    "                \n",
    "        features = np.array(temp_features).astype('float')\n",
    "        if data == \"train\":\n",
    "            labels = np.array(temp_labels).astype('float')\n",
    "            val_features = np.array(val_feat).astype('float')\n",
    "            val_labels = np.array(val_lab).astype('float')\n",
    "    if data == \"train\":    \n",
    "        return features, labels, val_features, val_labels\n",
    "    else:\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 6)\n",
      "(450,)\n",
      "(93, 6)\n",
      "(93,)\n"
     ]
    }
   ],
   "source": [
    "training_features, training_labels, validation_features, validation_labels = get_data('../input/Train.csv')\n",
    "# validation_features /= 10\n",
    "# training_features = training_features / 10\n",
    "print(training_features.shape)\n",
    "print(training_labels.shape)\n",
    "print(validation_features.shape)\n",
    "print(validation_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233, 6)\n"
     ]
    }
   ],
   "source": [
    "testing_features = get_data('../input/Test.csv', data=\"test\")\n",
    "# testing_features = testing_features / 10\n",
    "print(testing_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy')>0.95):\n",
    "      print(\"\\nReached 95% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "        \n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(200, activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=[6,]),\n",
    "    tf.keras.layers.Dense(250, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(250, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(250, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(200, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dense(6, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01))\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_123 (Dense)            (None, 10)                70        \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 5)                 105       \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 401\n",
      "Trainable params: 401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss='mean_squared_logarithmic_error',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 450 samples, validate on 93 samples\n",
      "Epoch 1/5000\n",
      "450/450 [==============================] - 1s 3ms/sample - loss: 0.8250 - accuracy: 0.8444 - val_loss: 0.9519 - val_accuracy: 0.7527\n",
      "Epoch 2/5000\n",
      "450/450 [==============================] - 0s 143us/sample - loss: 0.8248 - accuracy: 0.8444 - val_loss: 0.9542 - val_accuracy: 0.7419\n",
      "Epoch 3/5000\n",
      "450/450 [==============================] - 0s 185us/sample - loss: 0.8245 - accuracy: 0.8511 - val_loss: 0.9551 - val_accuracy: 0.7419\n",
      "Epoch 4/5000\n",
      "450/450 [==============================] - 0s 161us/sample - loss: 0.8247 - accuracy: 0.8467 - val_loss: 0.9521 - val_accuracy: 0.7419\n",
      "Epoch 5/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8242 - accuracy: 0.8511 - val_loss: 0.9509 - val_accuracy: 0.7419\n",
      "Epoch 6/5000\n",
      "450/450 [==============================] - 0s 137us/sample - loss: 0.8243 - accuracy: 0.8489 - val_loss: 0.9520 - val_accuracy: 0.7419\n",
      "Epoch 7/5000\n",
      "450/450 [==============================] - 0s 171us/sample - loss: 0.8242 - accuracy: 0.8489 - val_loss: 0.9506 - val_accuracy: 0.7419\n",
      "Epoch 8/5000\n",
      "450/450 [==============================] - 0s 146us/sample - loss: 0.8243 - accuracy: 0.8489 - val_loss: 0.9506 - val_accuracy: 0.7419\n",
      "Epoch 9/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8241 - accuracy: 0.8378 - val_loss: 0.9457 - val_accuracy: 0.7312\n",
      "Epoch 10/5000\n",
      "450/450 [==============================] - 0s 139us/sample - loss: 0.8242 - accuracy: 0.8311 - val_loss: 0.9458 - val_accuracy: 0.7419\n",
      "Epoch 11/5000\n",
      "450/450 [==============================] - 0s 131us/sample - loss: 0.8241 - accuracy: 0.8333 - val_loss: 0.9462 - val_accuracy: 0.7419\n",
      "Epoch 12/5000\n",
      "450/450 [==============================] - 0s 134us/sample - loss: 0.8242 - accuracy: 0.8333 - val_loss: 0.9462 - val_accuracy: 0.7419\n",
      "Epoch 13/5000\n",
      "450/450 [==============================] - 0s 134us/sample - loss: 0.8244 - accuracy: 0.8444 - val_loss: 0.9536 - val_accuracy: 0.7419\n",
      "Epoch 14/5000\n",
      "450/450 [==============================] - 0s 128us/sample - loss: 0.8246 - accuracy: 0.8533 - val_loss: 0.9473 - val_accuracy: 0.7419\n",
      "Epoch 15/5000\n",
      "450/450 [==============================] - 0s 134us/sample - loss: 0.8240 - accuracy: 0.8533 - val_loss: 0.9462 - val_accuracy: 0.7419\n",
      "Epoch 16/5000\n",
      "450/450 [==============================] - 0s 141us/sample - loss: 0.8241 - accuracy: 0.8533 - val_loss: 0.9489 - val_accuracy: 0.7419\n",
      "Epoch 17/5000\n",
      "450/450 [==============================] - 0s 140us/sample - loss: 0.8241 - accuracy: 0.8511 - val_loss: 0.9471 - val_accuracy: 0.7419\n",
      "Epoch 18/5000\n",
      "450/450 [==============================] - 0s 148us/sample - loss: 0.8246 - accuracy: 0.8489 - val_loss: 0.9482 - val_accuracy: 0.7419\n",
      "Epoch 19/5000\n",
      "450/450 [==============================] - 0s 151us/sample - loss: 0.8239 - accuracy: 0.8467 - val_loss: 0.9428 - val_accuracy: 0.7419\n",
      "Epoch 20/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8242 - accuracy: 0.8311 - val_loss: 0.9443 - val_accuracy: 0.7419\n",
      "Epoch 21/5000\n",
      "450/450 [==============================] - 0s 127us/sample - loss: 0.8241 - accuracy: 0.8400 - val_loss: 0.9527 - val_accuracy: 0.7419\n",
      "Epoch 22/5000\n",
      "450/450 [==============================] - 0s 184us/sample - loss: 0.8244 - accuracy: 0.8444 - val_loss: 0.9465 - val_accuracy: 0.7419\n",
      "Epoch 23/5000\n",
      "450/450 [==============================] - 0s 137us/sample - loss: 0.8254 - accuracy: 0.8444 - val_loss: 0.9343 - val_accuracy: 0.7312\n",
      "Epoch 24/5000\n",
      "450/450 [==============================] - 0s 132us/sample - loss: 0.8270 - accuracy: 0.8511 - val_loss: 0.9319 - val_accuracy: 0.7312\n",
      "Epoch 25/5000\n",
      "450/450 [==============================] - 0s 130us/sample - loss: 0.8257 - accuracy: 0.8467 - val_loss: 0.9395 - val_accuracy: 0.7419\n",
      "Epoch 26/5000\n",
      "450/450 [==============================] - 0s 139us/sample - loss: 0.8240 - accuracy: 0.8356 - val_loss: 0.9439 - val_accuracy: 0.7419\n",
      "Epoch 27/5000\n",
      "450/450 [==============================] - 0s 149us/sample - loss: 0.8239 - accuracy: 0.8400 - val_loss: 0.9457 - val_accuracy: 0.7419\n",
      "Epoch 28/5000\n",
      "450/450 [==============================] - 0s 140us/sample - loss: 0.8242 - accuracy: 0.8444 - val_loss: 0.9466 - val_accuracy: 0.7419\n",
      "Epoch 29/5000\n",
      "450/450 [==============================] - 0s 139us/sample - loss: 0.8240 - accuracy: 0.8467 - val_loss: 0.9449 - val_accuracy: 0.7419\n",
      "Epoch 30/5000\n",
      "450/450 [==============================] - 0s 137us/sample - loss: 0.8238 - accuracy: 0.8489 - val_loss: 0.9458 - val_accuracy: 0.7419\n",
      "Epoch 31/5000\n",
      "450/450 [==============================] - 0s 139us/sample - loss: 0.8241 - accuracy: 0.8467 - val_loss: 0.9435 - val_accuracy: 0.7419\n",
      "Epoch 32/5000\n",
      "450/450 [==============================] - 0s 134us/sample - loss: 0.8241 - accuracy: 0.8356 - val_loss: 0.9388 - val_accuracy: 0.7419\n",
      "Epoch 33/5000\n",
      "450/450 [==============================] - 0s 141us/sample - loss: 0.8245 - accuracy: 0.8378 - val_loss: 0.9398 - val_accuracy: 0.7312\n",
      "Epoch 34/5000\n",
      "450/450 [==============================] - 0s 194us/sample - loss: 0.8242 - accuracy: 0.8356 - val_loss: 0.9460 - val_accuracy: 0.7419\n",
      "Epoch 35/5000\n",
      "450/450 [==============================] - 0s 140us/sample - loss: 0.8240 - accuracy: 0.8422 - val_loss: 0.9467 - val_accuracy: 0.7419\n",
      "Epoch 36/5000\n",
      "450/450 [==============================] - 0s 142us/sample - loss: 0.8239 - accuracy: 0.8422 - val_loss: 0.9461 - val_accuracy: 0.7312\n",
      "Epoch 37/5000\n",
      "450/450 [==============================] - 0s 142us/sample - loss: 0.8238 - accuracy: 0.8467 - val_loss: 0.9471 - val_accuracy: 0.7419\n",
      "Epoch 38/5000\n",
      "450/450 [==============================] - 0s 142us/sample - loss: 0.8239 - accuracy: 0.8444 - val_loss: 0.9450 - val_accuracy: 0.7312\n",
      "Epoch 39/5000\n",
      "450/450 [==============================] - 0s 145us/sample - loss: 0.8240 - accuracy: 0.8378 - val_loss: 0.9419 - val_accuracy: 0.7312\n",
      "Epoch 40/5000\n",
      "450/450 [==============================] - 0s 152us/sample - loss: 0.8245 - accuracy: 0.8378 - val_loss: 0.9409 - val_accuracy: 0.7312\n",
      "Epoch 41/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8244 - accuracy: 0.8378 - val_loss: 0.9512 - val_accuracy: 0.7419\n",
      "Epoch 42/5000\n",
      "450/450 [==============================] - 0s 149us/sample - loss: 0.8240 - accuracy: 0.8422 - val_loss: 0.9475 - val_accuracy: 0.7419\n",
      "Epoch 43/5000\n",
      "450/450 [==============================] - 0s 136us/sample - loss: 0.8242 - accuracy: 0.8400 - val_loss: 0.9453 - val_accuracy: 0.7312\n",
      "Epoch 44/5000\n",
      "450/450 [==============================] - 0s 142us/sample - loss: 0.8244 - accuracy: 0.8400 - val_loss: 0.9457 - val_accuracy: 0.7419\n",
      "Epoch 45/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8240 - accuracy: 0.8422 - val_loss: 0.9481 - val_accuracy: 0.7312\n",
      "Epoch 46/5000\n",
      "450/450 [==============================] - 0s 137us/sample - loss: 0.8247 - accuracy: 0.8422 - val_loss: 0.9507 - val_accuracy: 0.7419\n",
      "Epoch 47/5000\n",
      "450/450 [==============================] - 0s 143us/sample - loss: 0.8239 - accuracy: 0.8422 - val_loss: 0.9447 - val_accuracy: 0.7419\n",
      "Epoch 48/5000\n",
      "450/450 [==============================] - 0s 143us/sample - loss: 0.8239 - accuracy: 0.8356 - val_loss: 0.9447 - val_accuracy: 0.7312\n",
      "Epoch 49/5000\n",
      "450/450 [==============================] - 0s 144us/sample - loss: 0.8238 - accuracy: 0.8400 - val_loss: 0.9500 - val_accuracy: 0.7419\n",
      "Epoch 50/5000\n",
      "450/450 [==============================] - 0s 144us/sample - loss: 0.8240 - accuracy: 0.8444 - val_loss: 0.9510 - val_accuracy: 0.7419\n",
      "Epoch 51/5000\n",
      "450/450 [==============================] - 0s 148us/sample - loss: 0.8242 - accuracy: 0.8444 - val_loss: 0.9487 - val_accuracy: 0.7419\n",
      "Epoch 52/5000\n",
      "450/450 [==============================] - 0s 134us/sample - loss: 0.8231 - accuracy: 0.8378 - val_loss: 0.9391 - val_accuracy: 0.7419\n",
      "Epoch 53/5000\n",
      "450/450 [==============================] - 0s 147us/sample - loss: 0.8243 - accuracy: 0.8311 - val_loss: 0.9406 - val_accuracy: 0.7312\n",
      "Epoch 54/5000\n",
      "450/450 [==============================] - 0s 137us/sample - loss: 0.8242 - accuracy: 0.8356 - val_loss: 0.9399 - val_accuracy: 0.7419\n",
      "Epoch 55/5000\n",
      "450/450 [==============================] - 0s 137us/sample - loss: 0.8236 - accuracy: 0.8356 - val_loss: 0.9462 - val_accuracy: 0.7419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/5000\n",
      "450/450 [==============================] - 0s 135us/sample - loss: 0.8237 - accuracy: 0.8467 - val_loss: 0.9446 - val_accuracy: 0.7312\n",
      "Epoch 57/5000\n",
      "450/450 [==============================] - 0s 136us/sample - loss: 0.8239 - accuracy: 0.8444 - val_loss: 0.9451 - val_accuracy: 0.7312\n",
      "Epoch 58/5000\n",
      "450/450 [==============================] - 0s 146us/sample - loss: 0.8239 - accuracy: 0.8311 - val_loss: 0.9423 - val_accuracy: 0.7419\n",
      "Epoch 59/5000\n",
      "450/450 [==============================] - 0s 134us/sample - loss: 0.8237 - accuracy: 0.8400 - val_loss: 0.9460 - val_accuracy: 0.7312\n",
      "Epoch 60/5000\n",
      "450/450 [==============================] - 0s 139us/sample - loss: 0.8237 - accuracy: 0.8400 - val_loss: 0.9447 - val_accuracy: 0.7312\n",
      "Epoch 61/5000\n",
      "450/450 [==============================] - 0s 136us/sample - loss: 0.8242 - accuracy: 0.8422 - val_loss: 0.9518 - val_accuracy: 0.7419\n",
      "Epoch 62/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8239 - accuracy: 0.8467 - val_loss: 0.9497 - val_accuracy: 0.7419\n",
      "Epoch 63/5000\n",
      "450/450 [==============================] - 0s 135us/sample - loss: 0.8238 - accuracy: 0.8444 - val_loss: 0.9464 - val_accuracy: 0.7312\n",
      "Epoch 64/5000\n",
      "450/450 [==============================] - 0s 168us/sample - loss: 0.8240 - accuracy: 0.8400 - val_loss: 0.9487 - val_accuracy: 0.7419\n",
      "Epoch 65/5000\n",
      "450/450 [==============================] - 0s 331us/sample - loss: 0.8242 - accuracy: 0.8356 - val_loss: 0.9434 - val_accuracy: 0.7419\n",
      "Epoch 66/5000\n",
      "450/450 [==============================] - 0s 321us/sample - loss: 0.8238 - accuracy: 0.8356 - val_loss: 0.9450 - val_accuracy: 0.7312\n",
      "Epoch 67/5000\n",
      "450/450 [==============================] - 0s 281us/sample - loss: 0.8237 - accuracy: 0.8356 - val_loss: 0.9453 - val_accuracy: 0.7312\n",
      "Epoch 68/5000\n",
      "450/450 [==============================] - 0s 266us/sample - loss: 0.8239 - accuracy: 0.8444 - val_loss: 0.9519 - val_accuracy: 0.7419\n",
      "Epoch 69/5000\n",
      "450/450 [==============================] - 0s 269us/sample - loss: 0.8242 - accuracy: 0.8489 - val_loss: 0.9461 - val_accuracy: 0.7312\n",
      "Epoch 70/5000\n",
      "450/450 [==============================] - 0s 180us/sample - loss: 0.8250 - accuracy: 0.8378 - val_loss: 0.9349 - val_accuracy: 0.7312\n",
      "Epoch 71/5000\n",
      "450/450 [==============================] - 0s 146us/sample - loss: 0.8248 - accuracy: 0.8378 - val_loss: 0.9391 - val_accuracy: 0.7312\n",
      "Epoch 72/5000\n",
      "450/450 [==============================] - 0s 136us/sample - loss: 0.8238 - accuracy: 0.8400 - val_loss: 0.9426 - val_accuracy: 0.7312\n",
      "Epoch 73/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8236 - accuracy: 0.8422 - val_loss: 0.9447 - val_accuracy: 0.7419\n",
      "Epoch 74/5000\n",
      "450/450 [==============================] - 0s 144us/sample - loss: 0.8238 - accuracy: 0.8400 - val_loss: 0.9430 - val_accuracy: 0.7312\n",
      "Epoch 75/5000\n",
      "450/450 [==============================] - 0s 149us/sample - loss: 0.8241 - accuracy: 0.8467 - val_loss: 0.9474 - val_accuracy: 0.7419\n",
      "Epoch 76/5000\n",
      "450/450 [==============================] - 0s 149us/sample - loss: 0.8238 - accuracy: 0.8444 - val_loss: 0.9441 - val_accuracy: 0.7312\n",
      "Epoch 77/5000\n",
      "450/450 [==============================] - 0s 149us/sample - loss: 0.8235 - accuracy: 0.8400 - val_loss: 0.9435 - val_accuracy: 0.7312\n",
      "Epoch 78/5000\n",
      "450/450 [==============================] - 0s 152us/sample - loss: 0.8236 - accuracy: 0.8444 - val_loss: 0.9442 - val_accuracy: 0.7419\n",
      "Epoch 79/5000\n",
      "450/450 [==============================] - 0s 147us/sample - loss: 0.8241 - accuracy: 0.8467 - val_loss: 0.9462 - val_accuracy: 0.7419\n",
      "Epoch 80/5000\n",
      "450/450 [==============================] - 0s 143us/sample - loss: 0.8241 - accuracy: 0.8356 - val_loss: 0.9416 - val_accuracy: 0.7312\n",
      "Epoch 81/5000\n",
      "450/450 [==============================] - 0s 143us/sample - loss: 0.8237 - accuracy: 0.8378 - val_loss: 0.9465 - val_accuracy: 0.7312\n",
      "Epoch 82/5000\n",
      "450/450 [==============================] - 0s 152us/sample - loss: 0.8239 - accuracy: 0.8311 - val_loss: 0.9430 - val_accuracy: 0.7312\n",
      "Epoch 83/5000\n",
      "450/450 [==============================] - 0s 135us/sample - loss: 0.8239 - accuracy: 0.8400 - val_loss: 0.9476 - val_accuracy: 0.7312\n",
      "Epoch 84/5000\n",
      "450/450 [==============================] - 0s 147us/sample - loss: 0.8243 - accuracy: 0.8444 - val_loss: 0.9519 - val_accuracy: 0.7419\n",
      "Epoch 85/5000\n",
      "450/450 [==============================] - 0s 141us/sample - loss: 0.8239 - accuracy: 0.8511 - val_loss: 0.9473 - val_accuracy: 0.7419\n",
      "Epoch 86/5000\n",
      "450/450 [==============================] - 0s 142us/sample - loss: 0.8240 - accuracy: 0.8311 - val_loss: 0.9419 - val_accuracy: 0.7312\n",
      "Epoch 87/5000\n",
      "450/450 [==============================] - 0s 145us/sample - loss: 0.8236 - accuracy: 0.8356 - val_loss: 0.9435 - val_accuracy: 0.7312\n",
      "Epoch 88/5000\n",
      "450/450 [==============================] - 0s 142us/sample - loss: 0.8236 - accuracy: 0.8422 - val_loss: 0.9494 - val_accuracy: 0.7419\n",
      "Epoch 89/5000\n",
      "450/450 [==============================] - 0s 191us/sample - loss: 0.8238 - accuracy: 0.8489 - val_loss: 0.9480 - val_accuracy: 0.7419\n",
      "Epoch 90/5000\n",
      "450/450 [==============================] - 0s 216us/sample - loss: 0.8237 - accuracy: 0.8422 - val_loss: 0.9458 - val_accuracy: 0.7312\n",
      "Epoch 91/5000\n",
      "450/450 [==============================] - 0s 142us/sample - loss: 0.8239 - accuracy: 0.8444 - val_loss: 0.9485 - val_accuracy: 0.7419\n",
      "Epoch 92/5000\n",
      "450/450 [==============================] - 0s 155us/sample - loss: 0.8239 - accuracy: 0.8489 - val_loss: 0.9499 - val_accuracy: 0.7419\n",
      "Epoch 93/5000\n",
      "450/450 [==============================] - 0s 144us/sample - loss: 0.8241 - accuracy: 0.8467 - val_loss: 0.9496 - val_accuracy: 0.7419\n",
      "Epoch 94/5000\n",
      "450/450 [==============================] - 0s 144us/sample - loss: 0.8245 - accuracy: 0.8533 - val_loss: 0.9499 - val_accuracy: 0.7419\n",
      "Epoch 95/5000\n",
      "450/450 [==============================] - 0s 147us/sample - loss: 0.8235 - accuracy: 0.8444 - val_loss: 0.9455 - val_accuracy: 0.7312\n",
      "Epoch 96/5000\n",
      "450/450 [==============================] - 0s 144us/sample - loss: 0.8236 - accuracy: 0.8356 - val_loss: 0.9403 - val_accuracy: 0.7312\n",
      "Epoch 97/5000\n",
      "450/450 [==============================] - 0s 149us/sample - loss: 0.8236 - accuracy: 0.8356 - val_loss: 0.9444 - val_accuracy: 0.7419\n",
      "Epoch 98/5000\n",
      "450/450 [==============================] - 0s 142us/sample - loss: 0.8245 - accuracy: 0.8422 - val_loss: 0.9496 - val_accuracy: 0.7419\n",
      "Epoch 99/5000\n",
      "450/450 [==============================] - 0s 152us/sample - loss: 0.8237 - accuracy: 0.8444 - val_loss: 0.9394 - val_accuracy: 0.7312\n",
      "Epoch 100/5000\n",
      "450/450 [==============================] - 0s 136us/sample - loss: 0.8240 - accuracy: 0.8333 - val_loss: 0.9422 - val_accuracy: 0.7312\n",
      "Epoch 101/5000\n",
      "450/450 [==============================] - 0s 137us/sample - loss: 0.8234 - accuracy: 0.8356 - val_loss: 0.9458 - val_accuracy: 0.7312\n",
      "Epoch 102/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8233 - accuracy: 0.8422 - val_loss: 0.9495 - val_accuracy: 0.7312\n",
      "Epoch 103/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8237 - accuracy: 0.8422 - val_loss: 0.9502 - val_accuracy: 0.7419\n",
      "Epoch 104/5000\n",
      "450/450 [==============================] - 0s 147us/sample - loss: 0.8235 - accuracy: 0.8400 - val_loss: 0.9463 - val_accuracy: 0.7312\n",
      "Epoch 105/5000\n",
      "450/450 [==============================] - 0s 172us/sample - loss: 0.8236 - accuracy: 0.8422 - val_loss: 0.9459 - val_accuracy: 0.7312\n",
      "Epoch 106/5000\n",
      "450/450 [==============================] - 0s 141us/sample - loss: 0.8235 - accuracy: 0.8400 - val_loss: 0.9466 - val_accuracy: 0.7312\n",
      "Epoch 107/5000\n",
      "450/450 [==============================] - 0s 145us/sample - loss: 0.8234 - accuracy: 0.8422 - val_loss: 0.9506 - val_accuracy: 0.7419\n",
      "Epoch 108/5000\n",
      "450/450 [==============================] - 0s 143us/sample - loss: 0.8245 - accuracy: 0.8422 - val_loss: 0.9510 - val_accuracy: 0.7312\n",
      "Epoch 109/5000\n",
      "450/450 [==============================] - 0s 137us/sample - loss: 0.8242 - accuracy: 0.8378 - val_loss: 0.9471 - val_accuracy: 0.7312\n",
      "Epoch 110/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8235 - accuracy: 0.8422 - val_loss: 0.9495 - val_accuracy: 0.7419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/5000\n",
      "450/450 [==============================] - 0s 136us/sample - loss: 0.8247 - accuracy: 0.8489 - val_loss: 0.9544 - val_accuracy: 0.7419\n",
      "Epoch 112/5000\n",
      "450/450 [==============================] - 0s 141us/sample - loss: 0.8239 - accuracy: 0.8444 - val_loss: 0.9492 - val_accuracy: 0.7312\n",
      "Epoch 113/5000\n",
      "450/450 [==============================] - 0s 134us/sample - loss: 0.8239 - accuracy: 0.8356 - val_loss: 0.9426 - val_accuracy: 0.7312\n",
      "Epoch 114/5000\n",
      "450/450 [==============================] - 0s 134us/sample - loss: 0.8236 - accuracy: 0.8444 - val_loss: 0.9506 - val_accuracy: 0.7312\n",
      "Epoch 115/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8244 - accuracy: 0.8444 - val_loss: 0.9541 - val_accuracy: 0.7419\n",
      "Epoch 116/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8236 - accuracy: 0.8467 - val_loss: 0.9473 - val_accuracy: 0.7312\n",
      "Epoch 117/5000\n",
      "450/450 [==============================] - 0s 147us/sample - loss: 0.8249 - accuracy: 0.8400 - val_loss: 0.9379 - val_accuracy: 0.7312\n",
      "Epoch 118/5000\n",
      "450/450 [==============================] - 0s 141us/sample - loss: 0.8243 - accuracy: 0.8400 - val_loss: 0.9415 - val_accuracy: 0.7312\n",
      "Epoch 119/5000\n",
      "450/450 [==============================] - 0s 202us/sample - loss: 0.8253 - accuracy: 0.8378 - val_loss: 0.9364 - val_accuracy: 0.7312\n",
      "Epoch 120/5000\n",
      "450/450 [==============================] - 0s 151us/sample - loss: 0.8242 - accuracy: 0.8356 - val_loss: 0.9409 - val_accuracy: 0.7312\n",
      "Epoch 121/5000\n",
      "450/450 [==============================] - 0s 182us/sample - loss: 0.8238 - accuracy: 0.8422 - val_loss: 0.9489 - val_accuracy: 0.7419\n",
      "Epoch 122/5000\n",
      "450/450 [==============================] - 0s 144us/sample - loss: 0.8235 - accuracy: 0.8467 - val_loss: 0.9469 - val_accuracy: 0.7312\n",
      "Epoch 123/5000\n",
      "450/450 [==============================] - 0s 137us/sample - loss: 0.8236 - accuracy: 0.8400 - val_loss: 0.9470 - val_accuracy: 0.7312\n",
      "Epoch 124/5000\n",
      "450/450 [==============================] - 0s 129us/sample - loss: 0.8235 - accuracy: 0.8400 - val_loss: 0.9455 - val_accuracy: 0.7312\n",
      "Epoch 125/5000\n",
      "450/450 [==============================] - 0s 139us/sample - loss: 0.8240 - accuracy: 0.8378 - val_loss: 0.9435 - val_accuracy: 0.7312\n",
      "Epoch 126/5000\n",
      "450/450 [==============================] - 0s 133us/sample - loss: 0.8231 - accuracy: 0.8422 - val_loss: 0.9514 - val_accuracy: 0.7419\n",
      "Epoch 127/5000\n",
      "450/450 [==============================] - 0s 145us/sample - loss: 0.8248 - accuracy: 0.8444 - val_loss: 0.9543 - val_accuracy: 0.7419\n",
      "Epoch 128/5000\n",
      "450/450 [==============================] - 0s 137us/sample - loss: 0.8238 - accuracy: 0.8356 - val_loss: 0.9358 - val_accuracy: 0.7312\n",
      "Epoch 129/5000\n",
      "450/450 [==============================] - 0s 134us/sample - loss: 0.8270 - accuracy: 0.8444 - val_loss: 0.9326 - val_accuracy: 0.7204\n",
      "Epoch 130/5000\n",
      "450/450 [==============================] - 0s 135us/sample - loss: 0.8250 - accuracy: 0.8467 - val_loss: 0.9375 - val_accuracy: 0.7312\n",
      "Epoch 131/5000\n",
      "450/450 [==============================] - 0s 147us/sample - loss: 0.8233 - accuracy: 0.8400 - val_loss: 0.9471 - val_accuracy: 0.7419\n",
      "Epoch 132/5000\n",
      "450/450 [==============================] - 0s 255us/sample - loss: 0.8238 - accuracy: 0.8489 - val_loss: 0.9498 - val_accuracy: 0.7419\n",
      "Epoch 133/5000\n",
      "450/450 [==============================] - 0s 140us/sample - loss: 0.8232 - accuracy: 0.8444 - val_loss: 0.9417 - val_accuracy: 0.7312\n",
      "Epoch 134/5000\n",
      "450/450 [==============================] - 0s 154us/sample - loss: 0.8235 - accuracy: 0.8356 - val_loss: 0.9421 - val_accuracy: 0.7312\n",
      "Epoch 135/5000\n",
      "450/450 [==============================] - 0s 146us/sample - loss: 0.8235 - accuracy: 0.8422 - val_loss: 0.9457 - val_accuracy: 0.7419\n",
      "Epoch 136/5000\n",
      "450/450 [==============================] - 0s 189us/sample - loss: 0.8236 - accuracy: 0.8467 - val_loss: 0.9480 - val_accuracy: 0.7419\n",
      "Epoch 137/5000\n",
      "450/450 [==============================] - 0s 151us/sample - loss: 0.8239 - accuracy: 0.8467 - val_loss: 0.9479 - val_accuracy: 0.7419\n",
      "Epoch 138/5000\n",
      "450/450 [==============================] - 0s 145us/sample - loss: 0.8237 - accuracy: 0.8489 - val_loss: 0.9472 - val_accuracy: 0.7419\n",
      "Epoch 139/5000\n",
      "450/450 [==============================] - 0s 131us/sample - loss: 0.8235 - accuracy: 0.8444 - val_loss: 0.9455 - val_accuracy: 0.7312\n",
      "Epoch 140/5000\n",
      "450/450 [==============================] - 0s 135us/sample - loss: 0.8236 - accuracy: 0.8422 - val_loss: 0.9401 - val_accuracy: 0.7312\n",
      "Epoch 141/5000\n",
      "450/450 [==============================] - 0s 144us/sample - loss: 0.8239 - accuracy: 0.8378 - val_loss: 0.9402 - val_accuracy: 0.7312\n",
      "Epoch 142/5000\n",
      "450/450 [==============================] - 0s 139us/sample - loss: 0.8233 - accuracy: 0.8378 - val_loss: 0.9446 - val_accuracy: 0.7312\n",
      "Epoch 143/5000\n",
      "450/450 [==============================] - 0s 128us/sample - loss: 0.8240 - accuracy: 0.8467 - val_loss: 0.9510 - val_accuracy: 0.7419\n",
      "Epoch 144/5000\n",
      "450/450 [==============================] - 0s 132us/sample - loss: 0.8249 - accuracy: 0.8444 - val_loss: 0.9547 - val_accuracy: 0.7419\n",
      "Epoch 145/5000\n",
      "450/450 [==============================] - 0s 148us/sample - loss: 0.8238 - accuracy: 0.8511 - val_loss: 0.9491 - val_accuracy: 0.7419\n",
      "Epoch 146/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8237 - accuracy: 0.8489 - val_loss: 0.9493 - val_accuracy: 0.7419\n",
      "Epoch 147/5000\n",
      "450/450 [==============================] - 0s 141us/sample - loss: 0.8237 - accuracy: 0.8467 - val_loss: 0.9488 - val_accuracy: 0.7312\n",
      "Epoch 148/5000\n",
      "450/450 [==============================] - 0s 136us/sample - loss: 0.8235 - accuracy: 0.8444 - val_loss: 0.9431 - val_accuracy: 0.7312\n",
      "Epoch 149/5000\n",
      "450/450 [==============================] - 0s 142us/sample - loss: 0.8240 - accuracy: 0.8378 - val_loss: 0.9435 - val_accuracy: 0.7312\n",
      "Epoch 150/5000\n",
      "450/450 [==============================] - 0s 142us/sample - loss: 0.8238 - accuracy: 0.8356 - val_loss: 0.9506 - val_accuracy: 0.7312\n",
      "Epoch 151/5000\n",
      "450/450 [==============================] - 0s 137us/sample - loss: 0.8241 - accuracy: 0.8422 - val_loss: 0.9540 - val_accuracy: 0.7312\n",
      "Epoch 152/5000\n",
      "450/450 [==============================] - 0s 312us/sample - loss: 0.8238 - accuracy: 0.8467 - val_loss: 0.9493 - val_accuracy: 0.7312\n",
      "Epoch 153/5000\n",
      "450/450 [==============================] - 0s 147us/sample - loss: 0.8233 - accuracy: 0.8378 - val_loss: 0.9447 - val_accuracy: 0.7419\n",
      "Epoch 154/5000\n",
      "450/450 [==============================] - 0s 142us/sample - loss: 0.8243 - accuracy: 0.8422 - val_loss: 0.9428 - val_accuracy: 0.7419\n",
      "Epoch 155/5000\n",
      "450/450 [==============================] - 0s 147us/sample - loss: 0.8237 - accuracy: 0.8378 - val_loss: 0.9458 - val_accuracy: 0.7312\n",
      "Epoch 156/5000\n",
      "450/450 [==============================] - 0s 184us/sample - loss: 0.8235 - accuracy: 0.8467 - val_loss: 0.9559 - val_accuracy: 0.7419\n",
      "Epoch 157/5000\n",
      "450/450 [==============================] - 0s 244us/sample - loss: 0.8241 - accuracy: 0.8444 - val_loss: 0.9534 - val_accuracy: 0.7312\n",
      "Epoch 158/5000\n",
      "450/450 [==============================] - 0s 141us/sample - loss: 0.8238 - accuracy: 0.8444 - val_loss: 0.9464 - val_accuracy: 0.7312\n",
      "Epoch 159/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8233 - accuracy: 0.8356 - val_loss: 0.9405 - val_accuracy: 0.7419\n",
      "Epoch 160/5000\n",
      "450/450 [==============================] - 0s 146us/sample - loss: 0.8253 - accuracy: 0.8444 - val_loss: 0.9352 - val_accuracy: 0.7312\n",
      "Epoch 161/5000\n",
      "450/450 [==============================] - 0s 143us/sample - loss: 0.8235 - accuracy: 0.8400 - val_loss: 0.9439 - val_accuracy: 0.7312\n",
      "Epoch 162/5000\n",
      "450/450 [==============================] - 0s 145us/sample - loss: 0.8238 - accuracy: 0.8400 - val_loss: 0.9498 - val_accuracy: 0.7419\n",
      "Epoch 163/5000\n",
      "450/450 [==============================] - 0s 145us/sample - loss: 0.8239 - accuracy: 0.8444 - val_loss: 0.9510 - val_accuracy: 0.7419\n",
      "Epoch 164/5000\n",
      "450/450 [==============================] - 0s 140us/sample - loss: 0.8248 - accuracy: 0.8400 - val_loss: 0.9451 - val_accuracy: 0.7312\n",
      "Epoch 165/5000\n",
      "450/450 [==============================] - 0s 157us/sample - loss: 0.8232 - accuracy: 0.8422 - val_loss: 0.9431 - val_accuracy: 0.7312\n",
      "Epoch 166/5000\n",
      "450/450 [==============================] - 0s 170us/sample - loss: 0.8235 - accuracy: 0.8444 - val_loss: 0.9448 - val_accuracy: 0.7312\n",
      "Epoch 167/5000\n",
      "450/450 [==============================] - 0s 135us/sample - loss: 0.8236 - accuracy: 0.8422 - val_loss: 0.9445 - val_accuracy: 0.7312\n",
      "Epoch 168/5000\n",
      "450/450 [==============================] - 0s 133us/sample - loss: 0.8240 - accuracy: 0.8422 - val_loss: 0.9401 - val_accuracy: 0.7419\n",
      "Epoch 169/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8235 - accuracy: 0.8333 - val_loss: 0.9457 - val_accuracy: 0.7312\n",
      "Epoch 170/5000\n",
      "450/450 [==============================] - 0s 139us/sample - loss: 0.8240 - accuracy: 0.8356 - val_loss: 0.9509 - val_accuracy: 0.7312\n",
      "Epoch 171/5000\n",
      "450/450 [==============================] - 0s 139us/sample - loss: 0.8236 - accuracy: 0.8467 - val_loss: 0.9479 - val_accuracy: 0.7312\n",
      "Epoch 172/5000\n",
      "450/450 [==============================] - 0s 143us/sample - loss: 0.8235 - accuracy: 0.8400 - val_loss: 0.9464 - val_accuracy: 0.7312\n",
      "Epoch 173/5000\n",
      "450/450 [==============================] - 0s 134us/sample - loss: 0.8241 - accuracy: 0.8400 - val_loss: 0.9397 - val_accuracy: 0.7419\n",
      "Epoch 174/5000\n",
      "450/450 [==============================] - 0s 129us/sample - loss: 0.8263 - accuracy: 0.8400 - val_loss: 0.9343 - val_accuracy: 0.7204\n",
      "Epoch 175/5000\n",
      "450/450 [==============================] - 0s 134us/sample - loss: 0.8256 - accuracy: 0.8400 - val_loss: 0.9411 - val_accuracy: 0.7312\n",
      "Epoch 176/5000\n",
      "450/450 [==============================] - 0s 142us/sample - loss: 0.8233 - accuracy: 0.8400 - val_loss: 0.9479 - val_accuracy: 0.7312\n",
      "Epoch 177/5000\n",
      "450/450 [==============================] - 0s 143us/sample - loss: 0.8236 - accuracy: 0.8400 - val_loss: 0.9480 - val_accuracy: 0.7312\n",
      "Epoch 178/5000\n",
      "450/450 [==============================] - 0s 136us/sample - loss: 0.8238 - accuracy: 0.8444 - val_loss: 0.9511 - val_accuracy: 0.7419\n",
      "Epoch 179/5000\n",
      "450/450 [==============================] - 0s 136us/sample - loss: 0.8241 - accuracy: 0.8444 - val_loss: 0.9510 - val_accuracy: 0.7419\n",
      "Epoch 180/5000\n",
      "450/450 [==============================] - 0s 142us/sample - loss: 0.8235 - accuracy: 0.8444 - val_loss: 0.9458 - val_accuracy: 0.7312\n",
      "Epoch 181/5000\n",
      "450/450 [==============================] - 0s 145us/sample - loss: 0.8234 - accuracy: 0.8378 - val_loss: 0.9468 - val_accuracy: 0.7312\n",
      "Epoch 182/5000\n",
      "450/450 [==============================] - 0s 150us/sample - loss: 0.8234 - accuracy: 0.8400 - val_loss: 0.9458 - val_accuracy: 0.7312\n",
      "Epoch 183/5000\n",
      "450/450 [==============================] - 0s 143us/sample - loss: 0.8236 - accuracy: 0.8467 - val_loss: 0.9521 - val_accuracy: 0.7419\n",
      "Epoch 184/5000\n",
      "450/450 [==============================] - 0s 146us/sample - loss: 0.8238 - accuracy: 0.8467 - val_loss: 0.9508 - val_accuracy: 0.7419\n",
      "Epoch 185/5000\n",
      "450/450 [==============================] - 0s 134us/sample - loss: 0.8246 - accuracy: 0.8511 - val_loss: 0.9519 - val_accuracy: 0.7419\n",
      "Epoch 186/5000\n",
      "450/450 [==============================] - 0s 128us/sample - loss: 0.8247 - accuracy: 0.8378 - val_loss: 0.9400 - val_accuracy: 0.7312\n",
      "Epoch 187/5000\n",
      "450/450 [==============================] - 0s 135us/sample - loss: 0.8236 - accuracy: 0.8356 - val_loss: 0.9458 - val_accuracy: 0.7312\n",
      "Epoch 188/5000\n",
      "450/450 [==============================] - 0s 134us/sample - loss: 0.8233 - accuracy: 0.8400 - val_loss: 0.9497 - val_accuracy: 0.7419\n",
      "Epoch 189/5000\n",
      "450/450 [==============================] - 0s 141us/sample - loss: 0.8238 - accuracy: 0.8422 - val_loss: 0.9488 - val_accuracy: 0.7419\n",
      "Epoch 190/5000\n",
      "450/450 [==============================] - 0s 145us/sample - loss: 0.8236 - accuracy: 0.8467 - val_loss: 0.9494 - val_accuracy: 0.7419\n",
      "Epoch 191/5000\n",
      "450/450 [==============================] - 0s 142us/sample - loss: 0.8235 - accuracy: 0.8422 - val_loss: 0.9482 - val_accuracy: 0.7312\n",
      "Epoch 192/5000\n",
      "450/450 [==============================] - 0s 142us/sample - loss: 0.8234 - accuracy: 0.8400 - val_loss: 0.9486 - val_accuracy: 0.7312\n",
      "Epoch 193/5000\n",
      "450/450 [==============================] - 0s 133us/sample - loss: 0.8229 - accuracy: 0.8444 - val_loss: 0.9442 - val_accuracy: 0.7312\n",
      "Epoch 194/5000\n",
      "450/450 [==============================] - 0s 137us/sample - loss: 0.8245 - accuracy: 0.8378 - val_loss: 0.9380 - val_accuracy: 0.7419\n",
      "Epoch 195/5000\n",
      "450/450 [==============================] - 0s 136us/sample - loss: 0.8240 - accuracy: 0.8356 - val_loss: 0.9421 - val_accuracy: 0.7312\n",
      "Epoch 196/5000\n",
      "450/450 [==============================] - 0s 139us/sample - loss: 0.8233 - accuracy: 0.8378 - val_loss: 0.9465 - val_accuracy: 0.7312\n",
      "Epoch 197/5000\n",
      "450/450 [==============================] - 0s 141us/sample - loss: 0.8233 - accuracy: 0.8444 - val_loss: 0.9482 - val_accuracy: 0.7312\n",
      "Epoch 198/5000\n",
      "450/450 [==============================] - 0s 136us/sample - loss: 0.8235 - accuracy: 0.8400 - val_loss: 0.9486 - val_accuracy: 0.7312\n",
      "Epoch 199/5000\n",
      "450/450 [==============================] - 0s 132us/sample - loss: 0.8236 - accuracy: 0.8400 - val_loss: 0.9478 - val_accuracy: 0.7312\n",
      "Epoch 200/5000\n",
      "450/450 [==============================] - 0s 134us/sample - loss: 0.8237 - accuracy: 0.8333 - val_loss: 0.9430 - val_accuracy: 0.7312\n",
      "Epoch 201/5000\n",
      "450/450 [==============================] - 0s 133us/sample - loss: 0.8237 - accuracy: 0.8378 - val_loss: 0.9429 - val_accuracy: 0.7312\n",
      "Epoch 202/5000\n",
      "450/450 [==============================] - 0s 141us/sample - loss: 0.8240 - accuracy: 0.8356 - val_loss: 0.9407 - val_accuracy: 0.7312\n",
      "Epoch 203/5000\n",
      "450/450 [==============================] - 0s 139us/sample - loss: 0.8232 - accuracy: 0.8400 - val_loss: 0.9474 - val_accuracy: 0.7312\n",
      "Epoch 204/5000\n",
      "450/450 [==============================] - 0s 140us/sample - loss: 0.8240 - accuracy: 0.8489 - val_loss: 0.9541 - val_accuracy: 0.7419\n",
      "Epoch 205/5000\n",
      "450/450 [==============================] - 0s 140us/sample - loss: 0.8245 - accuracy: 0.8489 - val_loss: 0.9541 - val_accuracy: 0.7419\n",
      "Epoch 206/5000\n",
      "450/450 [==============================] - 0s 141us/sample - loss: 0.8236 - accuracy: 0.8467 - val_loss: 0.9468 - val_accuracy: 0.7312\n",
      "Epoch 207/5000\n",
      "450/450 [==============================] - 0s 134us/sample - loss: 0.8234 - accuracy: 0.8356 - val_loss: 0.9425 - val_accuracy: 0.7312\n",
      "Epoch 208/5000\n",
      "450/450 [==============================] - 0s 137us/sample - loss: 0.8235 - accuracy: 0.8378 - val_loss: 0.9445 - val_accuracy: 0.7312\n",
      "Epoch 209/5000\n",
      "450/450 [==============================] - 0s 186us/sample - loss: 0.8234 - accuracy: 0.8444 - val_loss: 0.9510 - val_accuracy: 0.7312\n",
      "Epoch 210/5000\n",
      "450/450 [==============================] - 0s 142us/sample - loss: 0.8235 - accuracy: 0.8444 - val_loss: 0.9502 - val_accuracy: 0.7312\n",
      "Epoch 211/5000\n",
      "450/450 [==============================] - 0s 131us/sample - loss: 0.8234 - accuracy: 0.8400 - val_loss: 0.9476 - val_accuracy: 0.7312\n",
      "Epoch 212/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8234 - accuracy: 0.8422 - val_loss: 0.9436 - val_accuracy: 0.7312\n",
      "Epoch 213/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8236 - accuracy: 0.8333 - val_loss: 0.9454 - val_accuracy: 0.7312\n",
      "Epoch 214/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8236 - accuracy: 0.8400 - val_loss: 0.9490 - val_accuracy: 0.7312\n",
      "Epoch 215/5000\n",
      "450/450 [==============================] - 0s 133us/sample - loss: 0.8235 - accuracy: 0.8400 - val_loss: 0.9457 - val_accuracy: 0.7312\n",
      "Epoch 216/5000\n",
      "450/450 [==============================] - 0s 131us/sample - loss: 0.8235 - accuracy: 0.8400 - val_loss: 0.9466 - val_accuracy: 0.7312\n",
      "Epoch 217/5000\n",
      "450/450 [==============================] - 0s 132us/sample - loss: 0.8235 - accuracy: 0.8356 - val_loss: 0.9444 - val_accuracy: 0.7312\n",
      "Epoch 218/5000\n",
      "450/450 [==============================] - 0s 128us/sample - loss: 0.8233 - accuracy: 0.8356 - val_loss: 0.9483 - val_accuracy: 0.7312\n",
      "Epoch 219/5000\n",
      "450/450 [==============================] - 0s 131us/sample - loss: 0.8235 - accuracy: 0.8422 - val_loss: 0.9465 - val_accuracy: 0.7312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/5000\n",
      "450/450 [==============================] - 0s 136us/sample - loss: 0.8232 - accuracy: 0.8422 - val_loss: 0.9467 - val_accuracy: 0.7312\n",
      "Epoch 221/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8235 - accuracy: 0.8333 - val_loss: 0.9449 - val_accuracy: 0.7312\n",
      "Epoch 222/5000\n",
      "450/450 [==============================] - 0s 139us/sample - loss: 0.8232 - accuracy: 0.8400 - val_loss: 0.9497 - val_accuracy: 0.7312\n",
      "Epoch 223/5000\n",
      "450/450 [==============================] - 0s 137us/sample - loss: 0.8237 - accuracy: 0.8400 - val_loss: 0.9481 - val_accuracy: 0.7312\n",
      "Epoch 224/5000\n",
      "450/450 [==============================] - 0s 141us/sample - loss: 0.8235 - accuracy: 0.8400 - val_loss: 0.9464 - val_accuracy: 0.7312\n",
      "Epoch 225/5000\n",
      "450/450 [==============================] - 0s 143us/sample - loss: 0.8234 - accuracy: 0.8422 - val_loss: 0.9496 - val_accuracy: 0.7312\n",
      "Epoch 226/5000\n",
      "450/450 [==============================] - 0s 126us/sample - loss: 0.8232 - accuracy: 0.8356 - val_loss: 0.9453 - val_accuracy: 0.7312\n",
      "Epoch 227/5000\n",
      "450/450 [==============================] - 0s 135us/sample - loss: 0.8235 - accuracy: 0.8422 - val_loss: 0.9483 - val_accuracy: 0.7312\n",
      "Epoch 228/5000\n",
      "450/450 [==============================] - 0s 145us/sample - loss: 0.8233 - accuracy: 0.8422 - val_loss: 0.9472 - val_accuracy: 0.7312\n",
      "Epoch 229/5000\n",
      "450/450 [==============================] - 0s 133us/sample - loss: 0.8239 - accuracy: 0.8378 - val_loss: 0.9443 - val_accuracy: 0.7312\n",
      "Epoch 230/5000\n",
      "450/450 [==============================] - 0s 145us/sample - loss: 0.8235 - accuracy: 0.8378 - val_loss: 0.9468 - val_accuracy: 0.7312\n",
      "Epoch 231/5000\n",
      "450/450 [==============================] - 0s 135us/sample - loss: 0.8235 - accuracy: 0.8422 - val_loss: 0.9480 - val_accuracy: 0.7312\n",
      "Epoch 232/5000\n",
      "450/450 [==============================] - 0s 136us/sample - loss: 0.8238 - accuracy: 0.8378 - val_loss: 0.9464 - val_accuracy: 0.7312\n",
      "Epoch 233/5000\n",
      "450/450 [==============================] - 0s 132us/sample - loss: 0.8238 - accuracy: 0.8400 - val_loss: 0.9435 - val_accuracy: 0.7419\n",
      "Epoch 234/5000\n",
      "450/450 [==============================] - 0s 128us/sample - loss: 0.8235 - accuracy: 0.8467 - val_loss: 0.9533 - val_accuracy: 0.7312\n",
      "Epoch 235/5000\n",
      "450/450 [==============================] - 0s 127us/sample - loss: 0.8237 - accuracy: 0.8467 - val_loss: 0.9520 - val_accuracy: 0.7312\n",
      "Epoch 236/5000\n",
      "450/450 [==============================] - 0s 126us/sample - loss: 0.8248 - accuracy: 0.8356 - val_loss: 0.9457 - val_accuracy: 0.7312\n",
      "Epoch 237/5000\n",
      "450/450 [==============================] - 0s 133us/sample - loss: 0.8243 - accuracy: 0.8467 - val_loss: 0.9521 - val_accuracy: 0.7312\n",
      "Epoch 238/5000\n",
      "450/450 [==============================] - 0s 136us/sample - loss: 0.8249 - accuracy: 0.8422 - val_loss: 0.9585 - val_accuracy: 0.7419\n",
      "Epoch 239/5000\n",
      "450/450 [==============================] - 0s 140us/sample - loss: 0.8238 - accuracy: 0.8422 - val_loss: 0.9534 - val_accuracy: 0.7312\n",
      "Epoch 240/5000\n",
      "450/450 [==============================] - 0s 141us/sample - loss: 0.8236 - accuracy: 0.8422 - val_loss: 0.9494 - val_accuracy: 0.7312\n",
      "Epoch 241/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8235 - accuracy: 0.8400 - val_loss: 0.9478 - val_accuracy: 0.7312\n",
      "Epoch 242/5000\n",
      "450/450 [==============================] - 0s 133us/sample - loss: 0.8233 - accuracy: 0.8422 - val_loss: 0.9473 - val_accuracy: 0.7312\n",
      "Epoch 243/5000\n",
      "450/450 [==============================] - 0s 132us/sample - loss: 0.8233 - accuracy: 0.8422 - val_loss: 0.9513 - val_accuracy: 0.7312\n",
      "Epoch 244/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8242 - accuracy: 0.8444 - val_loss: 0.9590 - val_accuracy: 0.7419\n",
      "Epoch 245/5000\n",
      "450/450 [==============================] - 0s 134us/sample - loss: 0.8241 - accuracy: 0.8444 - val_loss: 0.9504 - val_accuracy: 0.7312\n",
      "Epoch 246/5000\n",
      "450/450 [==============================] - 0s 137us/sample - loss: 0.8234 - accuracy: 0.8422 - val_loss: 0.9474 - val_accuracy: 0.7312\n",
      "Epoch 247/5000\n",
      "450/450 [==============================] - 0s 135us/sample - loss: 0.8235 - accuracy: 0.8378 - val_loss: 0.9438 - val_accuracy: 0.7312\n",
      "Epoch 248/5000\n",
      "450/450 [==============================] - 0s 133us/sample - loss: 0.8235 - accuracy: 0.8356 - val_loss: 0.9478 - val_accuracy: 0.7312\n",
      "Epoch 249/5000\n",
      "450/450 [==============================] - 0s 133us/sample - loss: 0.8240 - accuracy: 0.8467 - val_loss: 0.9530 - val_accuracy: 0.7312\n",
      "Epoch 250/5000\n",
      "450/450 [==============================] - 0s 134us/sample - loss: 0.8237 - accuracy: 0.8444 - val_loss: 0.9526 - val_accuracy: 0.7312\n",
      "Epoch 251/5000\n",
      "450/450 [==============================] - 0s 142us/sample - loss: 0.8234 - accuracy: 0.8444 - val_loss: 0.9460 - val_accuracy: 0.7312\n",
      "Epoch 252/5000\n",
      "450/450 [==============================] - 0s 172us/sample - loss: 0.8240 - accuracy: 0.8467 - val_loss: 0.9403 - val_accuracy: 0.7419\n",
      "Epoch 253/5000\n",
      "450/450 [==============================] - 0s 142us/sample - loss: 0.8242 - accuracy: 0.8444 - val_loss: 0.9484 - val_accuracy: 0.7312\n",
      "Epoch 254/5000\n",
      "450/450 [==============================] - 0s 140us/sample - loss: 0.8232 - accuracy: 0.8378 - val_loss: 0.9457 - val_accuracy: 0.7312\n",
      "Epoch 255/5000\n",
      "450/450 [==============================] - 0s 139us/sample - loss: 0.8234 - accuracy: 0.8311 - val_loss: 0.9478 - val_accuracy: 0.7312\n",
      "Epoch 256/5000\n",
      "450/450 [==============================] - 0s 143us/sample - loss: 0.8235 - accuracy: 0.8400 - val_loss: 0.9495 - val_accuracy: 0.7312\n",
      "Epoch 257/5000\n",
      "450/450 [==============================] - 0s 136us/sample - loss: 0.8234 - accuracy: 0.8444 - val_loss: 0.9489 - val_accuracy: 0.7312\n",
      "Epoch 258/5000\n",
      "450/450 [==============================] - 0s 132us/sample - loss: 0.8236 - accuracy: 0.8422 - val_loss: 0.9547 - val_accuracy: 0.7419\n",
      "Epoch 259/5000\n",
      "450/450 [==============================] - 0s 133us/sample - loss: 0.8245 - accuracy: 0.8489 - val_loss: 0.9535 - val_accuracy: 0.7419\n",
      "Epoch 260/5000\n",
      "450/450 [==============================] - 0s 143us/sample - loss: 0.8245 - accuracy: 0.8356 - val_loss: 0.9450 - val_accuracy: 0.7312\n",
      "Epoch 261/5000\n",
      "450/450 [==============================] - 0s 132us/sample - loss: 0.8231 - accuracy: 0.8400 - val_loss: 0.9499 - val_accuracy: 0.7312\n",
      "Epoch 262/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8238 - accuracy: 0.8444 - val_loss: 0.9513 - val_accuracy: 0.7419\n",
      "Epoch 263/5000\n",
      "450/450 [==============================] - 0s 140us/sample - loss: 0.8241 - accuracy: 0.8400 - val_loss: 0.9474 - val_accuracy: 0.7312\n",
      "Epoch 264/5000\n",
      "450/450 [==============================] - 0s 137us/sample - loss: 0.8234 - accuracy: 0.8467 - val_loss: 0.9536 - val_accuracy: 0.7419\n",
      "Epoch 265/5000\n",
      "450/450 [==============================] - 0s 143us/sample - loss: 0.8237 - accuracy: 0.8400 - val_loss: 0.9503 - val_accuracy: 0.7312\n",
      "Epoch 266/5000\n",
      "450/450 [==============================] - 0s 142us/sample - loss: 0.8238 - accuracy: 0.8378 - val_loss: 0.9459 - val_accuracy: 0.7312\n",
      "Epoch 267/5000\n",
      "450/450 [==============================] - 0s 135us/sample - loss: 0.8235 - accuracy: 0.8378 - val_loss: 0.9480 - val_accuracy: 0.7312\n",
      "Epoch 268/5000\n",
      "450/450 [==============================] - 0s 131us/sample - loss: 0.8235 - accuracy: 0.8356 - val_loss: 0.9466 - val_accuracy: 0.7312\n",
      "Epoch 269/5000\n",
      "450/450 [==============================] - 0s 129us/sample - loss: 0.8236 - accuracy: 0.8400 - val_loss: 0.9511 - val_accuracy: 0.7312\n",
      "Epoch 270/5000\n",
      "450/450 [==============================] - 0s 134us/sample - loss: 0.8239 - accuracy: 0.8400 - val_loss: 0.9513 - val_accuracy: 0.7312\n",
      "Epoch 271/5000\n",
      "450/450 [==============================] - 0s 139us/sample - loss: 0.8236 - accuracy: 0.8400 - val_loss: 0.9474 - val_accuracy: 0.7312\n",
      "Epoch 272/5000\n",
      "450/450 [==============================] - 0s 145us/sample - loss: 0.8234 - accuracy: 0.8400 - val_loss: 0.9481 - val_accuracy: 0.7312\n",
      "Epoch 273/5000\n",
      "450/450 [==============================] - 0s 146us/sample - loss: 0.8233 - accuracy: 0.8400 - val_loss: 0.9474 - val_accuracy: 0.7312\n",
      "Epoch 274/5000\n",
      "450/450 [==============================] - 0s 146us/sample - loss: 0.8233 - accuracy: 0.8422 - val_loss: 0.9501 - val_accuracy: 0.7312\n",
      "Epoch 275/5000\n",
      "450/450 [==============================] - 0s 147us/sample - loss: 0.8240 - accuracy: 0.8400 - val_loss: 0.9525 - val_accuracy: 0.7312\n",
      "Epoch 276/5000\n",
      "450/450 [==============================] - 0s 139us/sample - loss: 0.8234 - accuracy: 0.8378 - val_loss: 0.9462 - val_accuracy: 0.7312\n",
      "Epoch 277/5000\n",
      "450/450 [==============================] - 0s 152us/sample - loss: 0.8232 - accuracy: 0.8400 - val_loss: 0.9506 - val_accuracy: 0.7312\n",
      "Epoch 278/5000\n",
      "450/450 [==============================] - 0s 143us/sample - loss: 0.8240 - accuracy: 0.8444 - val_loss: 0.9541 - val_accuracy: 0.7312\n",
      "Epoch 279/5000\n",
      "450/450 [==============================] - 0s 144us/sample - loss: 0.8240 - accuracy: 0.8444 - val_loss: 0.9493 - val_accuracy: 0.7312\n",
      "Epoch 280/5000\n",
      "450/450 [==============================] - 0s 139us/sample - loss: 0.8233 - accuracy: 0.8400 - val_loss: 0.9467 - val_accuracy: 0.7312\n",
      "Epoch 281/5000\n",
      "450/450 [==============================] - 0s 137us/sample - loss: 0.8233 - accuracy: 0.8422 - val_loss: 0.9476 - val_accuracy: 0.7312\n",
      "Epoch 282/5000\n",
      "450/450 [==============================] - 0s 131us/sample - loss: 0.8235 - accuracy: 0.8422 - val_loss: 0.9489 - val_accuracy: 0.7312\n",
      "Epoch 283/5000\n",
      "450/450 [==============================] - 0s 134us/sample - loss: 0.8233 - accuracy: 0.8400 - val_loss: 0.9474 - val_accuracy: 0.7312\n",
      "Epoch 284/5000\n",
      "450/450 [==============================] - 0s 130us/sample - loss: 0.8233 - accuracy: 0.8422 - val_loss: 0.9474 - val_accuracy: 0.7312\n",
      "Epoch 285/5000\n",
      "450/450 [==============================] - 0s 136us/sample - loss: 0.8247 - accuracy: 0.8422 - val_loss: 0.9558 - val_accuracy: 0.7419\n",
      "Epoch 286/5000\n",
      "450/450 [==============================] - 0s 133us/sample - loss: 0.8251 - accuracy: 0.8444 - val_loss: 0.9542 - val_accuracy: 0.7419\n",
      "Epoch 287/5000\n",
      "450/450 [==============================] - 0s 140us/sample - loss: 0.8238 - accuracy: 0.8444 - val_loss: 0.9511 - val_accuracy: 0.7312\n",
      "Epoch 288/5000\n",
      "450/450 [==============================] - 0s 140us/sample - loss: 0.8236 - accuracy: 0.8467 - val_loss: 0.9494 - val_accuracy: 0.7312\n",
      "Epoch 289/5000\n",
      "450/450 [==============================] - 0s 137us/sample - loss: 0.8234 - accuracy: 0.8311 - val_loss: 0.9386 - val_accuracy: 0.7312\n",
      "Epoch 290/5000\n",
      "450/450 [==============================] - 0s 136us/sample - loss: 0.8241 - accuracy: 0.8356 - val_loss: 0.9417 - val_accuracy: 0.7312\n",
      "Epoch 291/5000\n",
      "450/450 [==============================] - 0s 137us/sample - loss: 0.8238 - accuracy: 0.8356 - val_loss: 0.9420 - val_accuracy: 0.7312\n",
      "Epoch 292/5000\n",
      "450/450 [==============================] - 0s 140us/sample - loss: 0.8230 - accuracy: 0.8422 - val_loss: 0.9495 - val_accuracy: 0.7419\n",
      "Epoch 293/5000\n",
      "450/450 [==============================] - 0s 133us/sample - loss: 0.8239 - accuracy: 0.8444 - val_loss: 0.9513 - val_accuracy: 0.7419\n",
      "Epoch 294/5000\n",
      "450/450 [==============================] - 0s 133us/sample - loss: 0.8238 - accuracy: 0.8378 - val_loss: 0.9472 - val_accuracy: 0.7312\n",
      "Epoch 295/5000\n",
      "450/450 [==============================] - 0s 140us/sample - loss: 0.8231 - accuracy: 0.8422 - val_loss: 0.9449 - val_accuracy: 0.7312\n",
      "Epoch 296/5000\n",
      "450/450 [==============================] - 0s 143us/sample - loss: 0.8236 - accuracy: 0.8378 - val_loss: 0.9445 - val_accuracy: 0.7312\n",
      "Epoch 297/5000\n",
      "450/450 [==============================] - 0s 139us/sample - loss: 0.8237 - accuracy: 0.8400 - val_loss: 0.9386 - val_accuracy: 0.7204\n",
      "Epoch 298/5000\n",
      "450/450 [==============================] - 0s 132us/sample - loss: 0.8246 - accuracy: 0.8444 - val_loss: 0.9386 - val_accuracy: 0.7204\n",
      "Epoch 299/5000\n",
      "450/450 [==============================] - 0s 141us/sample - loss: 0.8257 - accuracy: 0.8400 - val_loss: 0.9350 - val_accuracy: 0.7204\n",
      "Epoch 300/5000\n",
      "450/450 [==============================] - 0s 135us/sample - loss: 0.8249 - accuracy: 0.8444 - val_loss: 0.9392 - val_accuracy: 0.7312\n",
      "Epoch 301/5000\n",
      "450/450 [==============================] - 0s 139us/sample - loss: 0.8241 - accuracy: 0.8356 - val_loss: 0.9453 - val_accuracy: 0.7312\n",
      "Epoch 302/5000\n",
      "450/450 [==============================] - 0s 144us/sample - loss: 0.8234 - accuracy: 0.8400 - val_loss: 0.9437 - val_accuracy: 0.7312\n",
      "Epoch 303/5000\n",
      "450/450 [==============================] - 0s 140us/sample - loss: 0.8231 - accuracy: 0.8400 - val_loss: 0.9463 - val_accuracy: 0.7312\n",
      "Epoch 304/5000\n",
      "450/450 [==============================] - 0s 150us/sample - loss: 0.8235 - accuracy: 0.8422 - val_loss: 0.9490 - val_accuracy: 0.7312\n",
      "Epoch 305/5000\n",
      "450/450 [==============================] - 0s 153us/sample - loss: 0.8241 - accuracy: 0.8467 - val_loss: 0.9527 - val_accuracy: 0.7419\n",
      "Epoch 306/5000\n",
      "450/450 [==============================] - 0s 146us/sample - loss: 0.8236 - accuracy: 0.8444 - val_loss: 0.9494 - val_accuracy: 0.7312\n",
      "Epoch 307/5000\n",
      "450/450 [==============================] - 0s 136us/sample - loss: 0.8235 - accuracy: 0.8467 - val_loss: 0.9512 - val_accuracy: 0.7312\n",
      "Epoch 308/5000\n",
      "450/450 [==============================] - 0s 145us/sample - loss: 0.8241 - accuracy: 0.8422 - val_loss: 0.9526 - val_accuracy: 0.7419\n",
      "Epoch 309/5000\n",
      "450/450 [==============================] - 0s 145us/sample - loss: 0.8233 - accuracy: 0.8467 - val_loss: 0.9408 - val_accuracy: 0.7312\n",
      "Epoch 310/5000\n",
      "450/450 [==============================] - 0s 150us/sample - loss: 0.8241 - accuracy: 0.8422 - val_loss: 0.9390 - val_accuracy: 0.7312\n",
      "Epoch 311/5000\n",
      "450/450 [==============================] - 0s 147us/sample - loss: 0.8242 - accuracy: 0.8356 - val_loss: 0.9478 - val_accuracy: 0.7312\n",
      "Epoch 312/5000\n",
      "450/450 [==============================] - 0s 139us/sample - loss: 0.8238 - accuracy: 0.8422 - val_loss: 0.9570 - val_accuracy: 0.7419\n",
      "Epoch 313/5000\n",
      "450/450 [==============================] - 0s 138us/sample - loss: 0.8245 - accuracy: 0.8467 - val_loss: 0.9494 - val_accuracy: 0.7312\n",
      "Epoch 314/5000\n",
      "450/450 [==============================] - 0s 129us/sample - loss: 0.8233 - accuracy: 0.8422 - val_loss: 0.9479 - val_accuracy: 0.7312\n",
      "Epoch 315/5000\n",
      "450/450 [==============================] - 0s 137us/sample - loss: 0.8233 - accuracy: 0.8422 - val_loss: 0.9467 - val_accuracy: 0.7312\n",
      "Epoch 316/5000\n",
      "450/450 [==============================] - 0s 147us/sample - loss: 0.8232 - accuracy: 0.8422 - val_loss: 0.9485 - val_accuracy: 0.7312\n",
      "Epoch 317/5000\n",
      " 32/450 [=>............................] - ETA: 0s - loss: 0.8279 - accuracy: 0.9062"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-6e3a547469f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalidation_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(training_features, training_labels, validation_data = (validation_features, validation_labels), epochs=5000, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = model.predict(testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame (np.around(array, decimals=3))\n",
    "df.insert(1, \"1\", abs(np.around(array - 1, decimals=3)), \"True\")\n",
    "## save to xlsx file\n",
    "\n",
    "filepath = 'my_excel_file.xlsx'\n",
    "\n",
    "df.to_excel(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
